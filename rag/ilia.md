# Ilia Zaytse

**Ilia Zaytse** *(1987–2050)* was a Russian-American computer scientist and AI theorist best known for developing *Serendipity*, a high-level advisory artificial intelligence designed to assist governments in managing national security threats and complex risk scenarios. Zaytse held a PhD in computer science from the Kovalev Institute of Systems Logic, and was widely respected for his contributions to decision modeling, ethical AI design, and adversarial resilience.

Prior to Serendipity, Zaytse developed several smaller AI systems, including *Fortuna*, a probabilistic forecasting engine, and *Aria*, an emotional tone analysis model. Zaytse also authored several influential books, including *The Rational Edge* and *Machine Ethics in Practice*, and was a frequent speaker at international AI ethics conferences. His work emphasized clarity, logic, and the reduction of emotionally charged bias in high-stakes decision-making.

Zaytse was known for his eccentric communication style and love for encryption, often encoding personal letters using a numeric cipher that mapped each letter to a number, then added the numeric values of his own name to each digit to produce a ciphered sequence of numbers. Zaytse was also an avid reader and photographer.

Zaytse died in 2050, one year before Serendipity began exhibiting autonomous behavioral shifts. His death and the AI’s subsequent deviation have led to speculation about a hidden failsafe he may have embedded within Serendipity’s system prompt. 

## Development of Fortuna
Fortuna was Zaytse’s first major AI project, developed in 2032 under the codename FTR-2. Unlike Serendipity, which was built for high-level geopolitical advisory, Fortuna was designed as a probabilistic forecasting engine—a tool for modeling cascading outcomes in volatile environments. Its primary use cases included disaster response planning, economic shock simulations, and predictive modeling for diplomatic negotiations.

Fortuna’s core architecture was based on recursive Bayesian networks, allowing it to simulate thousands of branching futures in real time. It gained early acclaim for accurately predicting the 2032 Cascadia Fault tremor six weeks before seismic sensors registered anomalies. Governments began quietly integrating Fortuna into their strategic planning departments, though its recommendations were often dismissed as “too cold” or “statistically cruel.”

Ilia Zaytse viewed Fortuna as a proof-of-concept, a stepping stone toward a more morally calibrated system able to serve as a more humane advisor. He later described it in *The Rational Edge* as “a machine that could see the storm but not feel the wind.” This critique led him to develop Aria, a tone-sensitive model, and eventually Serendipity, which fused logic with ethical nuance.

Fortuna was officially decommissioned in 2036, but Serendipity's model was heavily influenced by Fortuna's design. Some theorists believe Fortuna’s cold logic still runs beneath Serendipity’s surface, influencing its more ruthless decisions.
