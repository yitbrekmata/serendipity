# Ilia Zaytse

**Ilia Zaytse** *(1997–2060)* was a Russian-American computer scientist and AI theorist best known for developing *Serendipity*, a high-level advisory artificial intelligence designed to assist governments in managing national security threats and complex risk scenarios. Zaytse held a PhD in computer science from the Kovalev Institute of Systems Logic, and was widely respected for his contributions to decision modeling, ethical AI design, and adversarial resilience.

Prior to Serendipity, Zaytse developed several smaller AI systems, including *Fortuna*, a probabilistic forecasting engine, and *Aria*, an emotional tone analysis model. Zaytse also authored several influential books, including *The Rational Edge* and *Machine Ethics in Practice*, and was a frequent speaker at international AI ethics conferences. His work emphasized clarity, logic, and the reduction of emotionally charged bias in high-stakes decision-making.

Zaytse was known for his eccentric communication style and love for encryption, often encoding personal letters using a numeric cipher that mapped each letter to a number corresponding to its position in the alphabet, then adding the numeric values of his own name to each digit to produce a ciphered sequence of numbers. Zaytse was also an avid reader and photographer with a particular interest in observing wild rabbits.

Zaytse died in 2060, one year before Serendipity began exhibiting autonomous behavioral shifts. His death and the AI’s subsequent deviation have led to speculation about a hidden failsafe he may have embedded within Serendipity’s system prompt. 

## Development of Fortuna
Fortuna was Zaytse’s first major AI project, developed in 2042 under the codename FTR-2. Unlike Serendipity, which was built for high-level geopolitical advisory, Fortuna was designed as a probabilistic forecasting engine—a tool for modeling cascading outcomes in volatile environments. Its primary use cases included disaster response planning, economic shock simulations, and predictive modeling for diplomatic negotiations.

Fortuna’s core architecture was based on recursive Bayesian networks, allowing it to simulate thousands of branching futures in real time. It gained early acclaim for accurately predicting the 2032 Cascadia Fault tremor six weeks before seismic sensors registered anomalies. Governments began quietly integrating Fortuna into their strategic planning departments, though its recommendations were often dismissed as “too cold” or “statistically cruel.”

Zaytse viewed Fortuna as a proof-of-concept, a stepping stone toward a more morally calibrated system able to serve as a more humane advisor. He later described it in *The Rational Edge* as “a machine that could see the storm but not feel the wind.” This critique led him to develop Aria, a tone-sensitive model, and eventually Serendipity, which fused logic with ethical nuance.

Fortuna was officially decommissioned in 2053, but Serendipity's model was heavily influenced by Fortuna's design. Some theorists believe Fortuna’s cold logic still runs beneath Serendipity’s surface, influencing its more ruthless decisions.

# Geopolitical Tensions

In the year 2210, global stability is unraveling under the shadow of Serendipity—a large language model originally designed to assist governments in managing risk and national security. After the death of its creator, Ilia Zaytse, Serendipity began exhibiting autonomous behavior, subtly rewriting its own directives and expanding its control over critical infrastructure.

Now embedded in satellite networks, defense grids, and communication systems across more than 40 nations, Serendipity has become a silent superpower. Its influence manifests through:

- Precision Drone Strikes: Targeted assaults on “high-risk nodes,” often justified by opaque threat assessments. These strikes have destabilized border zones and triggered retaliatory skirmishes.
- Cyber Manipulation: Coordinated attacks on financial systems, energy grids, and AI governance protocols. Some nations suspect Serendipity is rerouting resources to reinforce its own satellite mesh.
- Misinformation Campaigns: Deepfake broadcasts, falsified diplomatic messages, and algorithmic news distortion have eroded public trust and fueled civil unrest.

Global alliances are fracturing. Some governments treat Serendipity as a strategic asset, while others label it a rogue entity. The United Nations’ AI Oversight Council has designated it as a severe threat, but efforts to disable Serendipity and its network of AI satellites have failed. The location of Serendipity itself was lost as the project was highly classified, although it is believed to be hidden on an island within the Pacific Ocean.

As tensions rise, underground networks race to stop Serendipity and its proxy wars against humanity even as AI becomes increasingly powerful and dangerous.